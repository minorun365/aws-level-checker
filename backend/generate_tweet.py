import boto3, json, os, requests
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_aws import ChatBedrockConverse
from langfuse.decorators import observe
from langfuse.callback import CallbackHandler

def create_response(status_code, message):
    return {
        "statusCode": status_code,
        "body": json.dumps(message)
    }

def lambda_handler(event, context):
    headers = {"X-Aws-Parameters-Secrets-Token": os.environ.get('AWS_SESSION_TOKEN')}
    secrets_extension_endpoint = os.environ["LANGFUSE_SECRET_URL"]
    r = requests.get(secrets_extension_endpoint, headers=headers)
    secret = json.loads(r.text)["SecretString"]
    
    if isinstance(secret, str):
        secret = json.loads(secret)

    llm = ChatBedrockConverse(
        model=os.environ["BEDROCK_INFERENCE_PROFILE_ARN"],
        max_tokens=4096,
    )

    langfuse_handler = CallbackHandler(
        secret_key=secret.get("LANGFUSE_SECRET_KEY"),
        public_key=secret.get("LANGFUSE_PUBLIC_KEY"),
        host=os.environ["LANGFUSE_HOST"],
        user_id=event.get("userEmail"),
        session_id=event.get("langfuseSessionId")
    )

    try:
        if not event.get("evalResult"):
            return create_response(400, {
                    "message": "ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã®å†…å®¹ãŒå…¥åŠ›ã•ã‚Œã¦ã„ãªã„ã‚ˆã†ã§ã™ğŸ¤”"
                }
            )

        prompt = ChatPromptTemplate.from_template("""
ä»¥ä¸‹ã¯ã€ã“ã®ã‚¢ãƒ—ãƒªã®åˆ©ç”¨è€…ãŒè‡ªåˆ†ã®æŠ€è¡“ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’è©•ä¾¡ã—ãŸçµæœã§ã™ã€‚
ã“ã‚Œã‚’Xã§ã¤ã¶ã‚„ã„ã¦ã‚¢ãƒ—ãƒªã®åˆ©ç”¨æ‹¡å¤§ã«ã¤ãªãŒã‚‹ã‚ˆã†ã€100æ–‡å­—ä»¥å†…ã®ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡è¨€ã«ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

<è©•ä¾¡çµæœ>
{eval_result}
</è©•ä¾¡çµæœ>

ä»¥ä¸‹ã®ä¾‹ã«æ²¿ã£ã¦ã€ãªã‚‹ã¹ã xxx ã®éƒ¨åˆ†ã ã‘ã‚’å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚

<ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡è¨€ã®ä¾‹>
#AWSãƒ¬ãƒ™ãƒ«åˆ¤å®šãã‚“ ã§xxxã«é–¢ã™ã‚‹ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã‚’è©•ä¾¡ã—ã¦ã¿ãŸã‚‰ã€Level xxxã§ã—ãŸï¼ ã¿ã‚“ãªã‚‚ä½¿ã£ã¦ã¿ã¦ã­ã€‚
https://checker.minoruonda.com/
</ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡è¨€ã®ä¾‹>

ãŸã ã—ã€Œã¯ã„ã€åˆ†ã‹ã‚Šã¾ã—ãŸã€‚ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡è¨€ã‚’ç”Ÿæˆã—ã¾ã™ã€ã¨ã„ã£ãŸå‰ç½®ãã¯ä¸è¦ã§ã™ã€‚
ãƒ„ã‚¤ãƒ¼ãƒˆæ–‡è¨€ãã®ã‚‚ã®ã ã‘ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚""")
        chain = prompt | llm | StrOutputParser()
        output = chain.invoke(
            input={"eval_result": event.get("evalResult")},
            config={
                "run_name": "Tweet Generation",
                "callbacks": [langfuse_handler]
            }
        )
        langfuse_handler.flush()
        
        return create_response(200, {
            "message": output,
            "traceId": langfuse_handler.get_trace_id()
        })

    except Exception as e:
        return create_response(500, {
            "message": f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}"
        })
